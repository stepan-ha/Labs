{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTfMTdnNRXkqYAZ5BlP4N2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepan-ha/Labs/blob/main/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Алгоритм розрахунку індивідуальних вхідних даних\n",
        "\n",
        "---\n",
        "\n",
        "Встановіть значення змінної variant: сума номера групи помноженого на 25 і\n",
        "порядкового номеру студента в списку групи (групі ПМОм-11 відповідає номер\n",
        "0, групі ПМІм-11 відповідає номер 1, групі ПМІм-12 відповідає номер 2, групі\n",
        "ПМІм-13 відповідає номер 3). Далі встановіть set.seed(variant) та згенеруйте\n",
        "значення змінної redundant як заокруглене до цілого (для заокруглення можна\n",
        "використати функції floor або round) випадкове число з рівномірного на інтервалі\n",
        "(номер групи + 5, 25 – номер групи) розподілу (функція runif). Також згенеруйте\n",
        "значення змінної year як заокруглене до цілого випадкове число з рівномірного\n",
        "на інтервалі (2006, 2008) розподілу.\n"
      ],
      "metadata": {
        "id": "R2q7SYKQEJwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "K8nI5kNUiug6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Розрахунок індивідуальних даних\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WxN2qSD93bDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_number = 2\n",
        "\n",
        "student_number = 5\n",
        "\n",
        "variant = group_number * 25 + student_number\n",
        "print(f\"Мій номер індивідуального завдання: {variant}\")\n",
        "\n",
        "np.random.seed(variant)\n",
        "\n",
        "redundant = math.floor(random.uniform(group_number + 5, 25 - group_number))\n",
        "print(f\"Redundant: {redundant}%\")\n",
        "\n",
        "year = np.random.randint(2006, 2008)\n",
        "\n",
        "print(year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puKQbQh23aah",
        "outputId": "2b8074b5-6d82-4146-b7fb-d16e6fd277a6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мій номер індивідуального завдання: 55\n",
            "Redundant: 10%\n",
            "2007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Допоміжні функції\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "FaOB5ZGq4-o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkKNAccuracy(x_train, y_train, x_test, y_test):\n",
        "  best_accuracy = 0\n",
        "  best_k = 1\n",
        "  for k in range(1, 21):\n",
        "      knn = KNeighborsClassifier(n_neighbors=k)\n",
        "      knn.fit(x_train, y_train)\n",
        "      accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "      if accuracy > best_accuracy:\n",
        "          best_accuracy = accuracy\n",
        "          best_k = k\n",
        "  print(f\"Найкраще K = {best_k}  з точністю: {best_accuracy}!\")\n",
        "\n",
        "\n",
        "def buildConfusionMatrix(y_test, prediction, methodName):\n",
        "  print(f\"\\nМатриця помилок для {methodName}:\")\n",
        "  print(confusion_matrix(y_test, prediction))\n"
      ],
      "metadata": {
        "id": "ht-GYwcB4-Ke"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "\n",
        "---\n",
        "\n",
        "Використовуючи дані Weekly, встановивши seed, що дорівнює значенню\n",
        "змінної variant, побудуйте модель логістичної регресії для передбачення\n",
        "Direction з використанням навчальних даних з 1990 по year рр., на основі єдиного\n",
        "предиктора Lag2. Обчисліть матрицю помилок та загальну частку правильних\n",
        "прогнозів на тестових даних (тобто даних за year-2010 роки). За аналогічних\n",
        "умов використайте для передбачення Direction лінійний дискримінантний аналіз,\n",
        "квадратичний дискримінантний аналіз та метод K-найближчих сусідів з K = 1.\n",
        "Порівняйте використані методи. За якого K точність методу K-найближчих\n",
        "сусідів буде найбільшою?"
      ],
      "metadata": {
        "id": "a13lzP7jEM5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv('Weekly.csv')\n",
        "\n",
        "train_data = data[(data['Year'] >= 1990) & (data['Year'] < year)]\n",
        "test_data = data[(data['Year'] >= year) & (data['Year'] <= 2010)]\n",
        "\n",
        "X_train = train_data[['Lag2']]\n",
        "y_train = train_data['Direction']\n",
        "X_test = test_data[['Lag2']]\n",
        "y_test = test_data['Direction']\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "y_pred_log = log_model.predict(X_test)\n",
        "\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "lda_model.fit(X_train, y_train)\n",
        "y_pred_lda = lda_model.predict(X_test)\n",
        "\n",
        "qda_model = QuadraticDiscriminantAnalysis()\n",
        "qda_model.fit(X_train, y_train)\n",
        "y_pred_qda = qda_model.predict(X_test)\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn1 = knn_model.predict(X_test)\n",
        "\n",
        "print(\"Точність моделі логістичної регресії:\", accuracy_score(y_test, y_pred_log))\n",
        "buildConfusionMatrix(y_test, y_pred_log, \"Моделі логістичної регресії\");\n",
        "\n",
        "print(\"Точність лінійного дискримінантного аналізу:\", accuracy_score(y_test, y_pred_lda))\n",
        "buildConfusionMatrix(y_test, y_pred_lda, \"Лінійного дискримінантного аналізу\");\n",
        "\n",
        "print(\"Точність квадратичного дискримінантного аналізу:\", accuracy_score(y_test, y_pred_qda))\n",
        "buildConfusionMatrix(y_test, y_pred_qda, \"Квадратичного дискримінантного аналізу\");\n",
        "\n",
        "print(\"Точність методу K-найближчих сусідів (K=1):\", accuracy_score(y_test, y_pred_knn1))\n",
        "buildConfusionMatrix(y_test, y_pred_knn1, \"Методу K-найближчих сусідів\");\n",
        "checkKNAccuracy(X_train, y_train, X_test, y_test);\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGMdWIHSBbQM",
        "outputId": "d5d6ab7a-3d38-4409-fbba-afbfae01c4c8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точність моделі логістичної регресії: 0.5502392344497608\n",
            "\n",
            "Матриця помилок для Моделі логістичної регресії:\n",
            "[[  5  91]\n",
            " [  3 110]]\n",
            "Точність лінійного дискримінантного аналізу: 0.5502392344497608\n",
            "\n",
            "Матриця помилок для Лінійного дискримінантного аналізу:\n",
            "[[  5  91]\n",
            " [  3 110]]\n",
            "Точність квадратичного дискримінантного аналізу: 0.5406698564593302\n",
            "\n",
            "Матриця помилок для Квадратичного дискримінантного аналізу:\n",
            "[[  0  96]\n",
            " [  0 113]]\n",
            "Точність методу K-найближчих сусідів (K=1): 0.5119617224880383\n",
            "\n",
            "Матриця помилок для Методу K-найближчих сусідів:\n",
            "[[49 47]\n",
            " [55 58]]\n",
            "Найкраще K = 19  з точністю: 0.5980861244019139!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вигляд матриці для аналізу\n",
        "\n",
        "---\n",
        "[\n",
        "\n",
        "  \n",
        "  [True Negative, False Positive]\n",
        "\n",
        "  [False Negative, True Positive]\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "520otNeI-8ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 2\n",
        "\n",
        "---\n",
        "\n",
        "Модифікуйте дані Auto наступним чином: встановивши seed, що дорівнює\n",
        "значенню змінної variant, видаліть redundant % спостережень з допомогою\n",
        "функції sample. Створіть двійкову змінну mpg01, яка містить 1, якщо mpg містить\n",
        "значення більше за середнє, і 0, якщо mpg містить значення менше за середнє.\n",
        "Розбийте дані на навчальний та тестовий набори. При розбитті набору даних\n",
        "обов’язково!!! встановити seed, що дорівнює значенню змінної variant, та\n",
        "використати функцію sample. Обсяг тестової вибірки виберіть 2*redundant % від\n",
        "загального обсягу даних. Застосуйте лінійний дискримінантний аналіз,\n",
        "квадратичний дискримінантний аналіз, логістичну регресію та метод Кнайближчих сусідів з різними значеннями для К на навчальних даних, щоб\n",
        "передбачити mpg01 на основі змінних weight, displacement та horsepower.\n",
        "Порівняйте тестові помилка використаних моделей. За якого K точність методу\n",
        "K-найближчих сусідів буде найбільшою та якою буде точність цього методу?"
      ],
      "metadata": {
        "id": "Orstg4Z61vUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_auto = pd.read_csv('Auto.csv')\n",
        "\n",
        "print(data_auto.head())\n",
        "\n",
        "Auto_new = data_auto.drop(data_auto.sample(frac=redundant / 100, random_state=variant).index)\n",
        "\n",
        "print(f\"Початковий розмір: {data_auto.shape}\")\n",
        "print(f\"Новий розмір: {Auto_new.shape}\")\n",
        "\n",
        "invalid_rows = Auto_new[Auto_new['horsepower'].apply(lambda x: isinstance(x, str) and x.strip() == '?')]\n",
        "\n",
        "Auto_new['horsepower'] = pd.to_numeric(Auto_new['horsepower'], errors='coerce')\n",
        "\n",
        "Auto_new = Auto_new.dropna(subset=['horsepower'])\n",
        "\n",
        "#цю валідацію, а також конвертацію я зробив через помилки,\n",
        "#які виникали під час лінійної регресії, а також щоб результат був максимально точним\n",
        "\n",
        "Auto_new['mpg01'] = np.where(Auto_new['mpg'] > Auto_new['mpg'].mean(), 1, 0)\n",
        "\n",
        "X = Auto_new[['weight', 'displacement', 'horsepower']]\n",
        "y = Auto_new['mpg01']\n",
        "\n",
        "sizeP = ((2*redundant)/100)\n",
        "\n",
        "print(f\"sizeP: {sizeP}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = sizeP, random_state=variant)\n",
        "\n",
        "log_model_auto = LogisticRegression()\n",
        "log_model_auto.fit(X_train, y_train)\n",
        "y_pred_log_auto = log_model_auto.predict(X_test)\n",
        "\n",
        "lda_model_auto = LinearDiscriminantAnalysis()\n",
        "lda_model_auto.fit(X_train, y_train)\n",
        "y_pred_lda_auto = lda_model_auto.predict(X_test)\n",
        "\n",
        "qda_model_auto = QuadraticDiscriminantAnalysis()\n",
        "qda_model_auto.fit(X_train, y_train)\n",
        "y_pred_qda_auto = qda_model_auto.predict(X_test)\n",
        "\n",
        "knn_model_auto = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_model_auto.fit(X_train, y_train)\n",
        "y_pred_knn1_auto = knn_model_auto.predict(X_test)\n",
        "\n",
        "print(\"Точність моделі логістичної регресії:\", accuracy_score(y_test, y_pred_log_auto))\n",
        "buildConfusionMatrix(y_test, y_pred_log_auto, \"Моделі логістичної регресії\")\n",
        "\n",
        "print(\"Точність лінійного дискримінантного аналізу:\", accuracy_score(y_test, y_pred_lda_auto))\n",
        "buildConfusionMatrix(y_test, y_pred_lda_auto, \"Лінійного дискримінантного аналізу\")\n",
        "\n",
        "print(\"Точність квадратичного дискримінантного аналізу:\", accuracy_score(y_test, y_pred_qda_auto))\n",
        "buildConfusionMatrix(y_test, y_pred_qda_auto, \"Квадратичного дискримінантного аналізу\")\n",
        "\n",
        "print(\"Точність методу K-найближчих сусідів (K=1):\", accuracy_score(y_test, y_pred_knn1_auto))\n",
        "buildConfusionMatrix(y_test, y_pred_knn1_auto, \"Методу K-найближчих сусідів\")\n",
        "\n",
        "checkKNAccuracy(X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dQXHmGZB_UN",
        "outputId": "c877e147-6f2c-4845-9f50-18daa8f35783"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
            "0  18.0          8         307.0        130    3504          12.0    70   \n",
            "1  15.0          8         350.0        165    3693          11.5    70   \n",
            "2  18.0          8         318.0        150    3436          11.0    70   \n",
            "3  16.0          8         304.0        150    3433          12.0    70   \n",
            "4  17.0          8         302.0        140    3449          10.5    70   \n",
            "\n",
            "   origin                       name  \n",
            "0       1  chevrolet chevelle malibu  \n",
            "1       1          buick skylark 320  \n",
            "2       1         plymouth satellite  \n",
            "3       1              amc rebel sst  \n",
            "4       1                ford torino  \n",
            "Початковий розмір: (397, 9)\n",
            "Новий розмір: (357, 9)\n",
            "sizeP: 0.2\n",
            "Точність моделі логістичної регресії: 0.8591549295774648\n",
            "\n",
            "Матриця помилок для Моделі логістичної регресії:\n",
            "[[33  8]\n",
            " [ 2 28]]\n",
            "Точність лінійного дискримінантного аналізу: 0.8169014084507042\n",
            "\n",
            "Матриця помилок для Лінійного дискримінантного аналізу:\n",
            "[[30 11]\n",
            " [ 2 28]]\n",
            "Точність квадратичного дискримінантного аналізу: 0.8732394366197183\n",
            "\n",
            "Матриця помилок для Квадратичного дискримінантного аналізу:\n",
            "[[35  6]\n",
            " [ 3 27]]\n",
            "Точність методу K-найближчих сусідів (K=1): 0.8450704225352113\n",
            "\n",
            "Матриця помилок для Методу K-найближчих сусідів:\n",
            "[[33  8]\n",
            " [ 3 27]]\n",
            "Найкраще K = 4  з точністю: 0.8591549295774648!\n"
          ]
        }
      ]
    }
  ]
}